{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Member.csv', './Order_TG.csv', './Order_TS.csv', './SalePage.csv', './Segment.csv']\n"
     ]
    }
   ],
   "source": [
    "# get all file in the directory\n",
    "\n",
    "def get_all_files(directory):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.csv') and not file.startswith('.') and not file.startswith('cleaned'):\n",
    "                all_files.append(os.path.join(root, file))\n",
    "    return all_files\n",
    "\n",
    "# get all files in current directory\n",
    "\n",
    "all_files = get_all_files('.')\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process Member.csv file\n",
    "\n",
    "pd_member = pd.read_csv('Member.csv')\n",
    "\n",
    "pd_member['RegisterDateTime'] = pd.to_datetime(pd_member['RegisterDateTime'], errors='coerce')\n",
    "\n",
    "# 100000 rows per chunk, write to a new csv file, under Member/year_month folder\n",
    "if not os.path.exists('Member'):\n",
    "    os.makedirs('Member')\n",
    "chunk_size = 100000\n",
    "chunks = [pd_member[i:i+chunk_size] for i in range(0, pd_member.shape[0], chunk_size)]\n",
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.to_csv('Member/cleaned_' + str(i) + '.csv', index=False)\n",
    "\n",
    "\n",
    "# unique_year_month = pd_member['RegisterDateTime'].dt.strftime('%Y-%m').unique()\n",
    "\n",
    "# for year_month in unique_year_month:\n",
    "#     # get the data in the same year_month\n",
    "#     df = pd_member[pd_member['RegisterDateTime'].dt.strftime('%Y-%m') == year_month]\n",
    "\n",
    "#     # 100000 rows per chunk, write to a new csv file, under Member/year_month folder\n",
    "#     # check if the \"Member\" folder exists\n",
    "#     if not os.path.exists('Member/' + year_month):\n",
    "#         os.makedirs('Member/' + year_month)\n",
    "#     chunk_size = 100000\n",
    "#     chunks = [df[i:i+chunk_size] for i in range(0, df.shape[0], chunk_size)]\n",
    "#     for i, chunk in enumerate(chunks):\n",
    "#         chunk.to_csv('Member/' + year_month + '/cleaned_' + year_month + '_' + str(i) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process Order_TG.csv file\n",
    "\n",
    "pd_Order_TG = pd.read_csv('Order_TG.csv')\n",
    "\n",
    "\n",
    "# get unique year month in \"HitTime\" column\n",
    "pd_Order_TG['OrderDateTime'] = pd.to_datetime(pd_Order_TG['OrderDateTime'], errors='coerce')\n",
    "# get rid of the rows with NaT\n",
    "pd_Order_TG = pd_Order_TG.dropna(subset=['OrderDateTime'])\n",
    "# Sort the data by \"OrderDateTime\"\n",
    "pd_Order_TG = pd_Order_TG.sort_values(by='OrderDateTime')\n",
    "unique_year_month = pd_Order_TG['OrderDateTime'].dt.strftime('%Y-%m').unique()\n",
    "print(unique_year_month)\n",
    "\n",
    "for year_month in unique_year_month:\n",
    "    # get the data in the same year_month\n",
    "    df = pd_Order_TG[pd_Order_TG['OrderDateTime'].dt.strftime('%Y-%m') == year_month]\n",
    "\n",
    "    # 100000 rows per chunk, write to a new csv file, under Order_TG/year_month folder\n",
    "    # check if the \"Order_TG\" folder exists\n",
    "    if not os.path.exists('Order_TG/' + year_month):\n",
    "        os.makedirs('Order_TG/' + year_month)\n",
    "    chunk_size = 100000\n",
    "    chunks = [df[i:i+chunk_size] for i in range(0, df.shape[0], chunk_size)]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk.to_csv('Order_TG/' + year_month + '/cleaned_' + year_month + '_' + str(i) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process Segment.csv file\n",
    "\n",
    "pd_Segment = pd.read_csv('Segment.csv')\n",
    "\n",
    "\n",
    "# get unique year month in \"HitTime\" column\n",
    "pd_Segment['DataSourceDate'] = pd.to_datetime(pd_Segment['DataSourceDate'], errors='coerce')\n",
    "# get rid of the rows with NaT\n",
    "pd_Segment = pd_Segment.dropna(subset=['DataSourceDate'])\n",
    "# sort the data by \"OrderDateTime\"\n",
    "pd_Segment = pd_Segment.sort_values(by='DataSourceDate')\n",
    "unique_year_month = pd_Segment['DataSourceDate'].dt.strftime('%Y-%m').unique()\n",
    "\n",
    "for year_month in unique_year_month:\n",
    "    # get the data in the same year_month\n",
    "    df = pd_Segment[pd_Segment['DataSourceDate'].dt.strftime('%Y-%m') == year_month]\n",
    "\n",
    "    # 100000 rows per chunk, write to a new csv file, under Segment/year_month folder\n",
    "    # check if the \"Order_TG\" folder exists\n",
    "    if not os.path.exists('Segment/' + year_month):\n",
    "        os.makedirs('Segment/' + year_month)\n",
    "    chunk_size = 100000\n",
    "    chunks = [df[i:i+chunk_size] for i in range(0, df.shape[0], chunk_size)]\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk.to_csv('Segment/' + year_month + '/cleaned_' + year_month + '_' + str(i) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/rxqxvrmd0z1bnnny3trbtfz80000gn/T/ipykernel_2548/2287899387.py:1: DtypeWarning: Columns (7,8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dffff = pd.read_csv('Order_TS.csv')\n"
     ]
    }
   ],
   "source": [
    "dffff = pd.read_csv('Order_TS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46524829\n"
     ]
    }
   ],
   "source": [
    "print(len(dffff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd_Order_TS = pd.read_csv('Order_TS.csv')\n",
    "pd_Order_TS = dffff\n",
    "\n",
    "# get unique year month in \"HitTime\" column\n",
    "pd_Order_TS['OrderDateTime'] = pd.to_datetime(pd_Order_TS['OrderDateTime'], errors='coerce')\n",
    "# get rid of the rows with NaT\n",
    "pd_Order_TS = pd_Order_TS.dropna(subset=['OrderDateTime'])\n",
    "\n",
    "chunk_size = 100000\n",
    "chunks = [pd_Order_TS[i:i+chunk_size] for i in range(0, pd_Order_TS.shape[0], chunk_size)]\n",
    "\n",
    "for j, chunk in enumerate(chunks):\n",
    "    tmp_df = chunk\n",
    "    tmp_df = tmp_df.sort_values(by='OrderDateTime')\n",
    "    unique_year_month = tmp_df['OrderDateTime'].dt.strftime('%Y-%m').unique()\n",
    "    \n",
    "    for year_month in unique_year_month:\n",
    "        # get the data in the same year_month\n",
    "        df = tmp_df[tmp_df['OrderDateTime'].dt.strftime('%Y-%m') == year_month]\n",
    "\n",
    "        # 100000 rows per chunk, write to a new csv file, under Order_TS/year_month folder\n",
    "        if not os.path.exists('Order_TS/' + year_month):\n",
    "            os.makedirs('Order_TS/' + year_month)\n",
    "        chunk_size = 100000\n",
    "        chunks = [df[i:i+chunk_size] for i in range(0, df.shape[0], chunk_size)]\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk.to_csv('Order_TS/' + year_month + '/cleaned_' + year_month + '_' + str(j) +'_' + str(i) + '.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "# for year_month in unique_year_month:\n",
    "#     print(year_month)\n",
    "#     # get the data in the same year_month\n",
    "#     df = pd_Order_TS[pd_Order_TS['OrderDateTime'].dt.strftime('%Y-%m') == year_month]\n",
    "\n",
    "#     # 100000 rows per chunk, write to a new csv file, under Order_TS/year_month folder\n",
    "    \n",
    "#     if not os.path.exists('Order_TS/' + year_month):\n",
    "#         os.makedirs('Order_TS/' + year_month)\n",
    "#     chunk_size = 100000\n",
    "#     chunks = [df[i:i+chunk_size] for i in range(0, df.shape[0], chunk_size)]\n",
    "#     for i, chunk in enumerate(chunks):\n",
    "#         chunk.to_csv('Order_TS/' + year_month + '/cleaned_' + year_month + '_' + str(i) + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
